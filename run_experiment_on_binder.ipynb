{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Optimizing the Photo-fenton model using Deep Reinforcement Learning\n",
    "\n",
    "In this notebook we show an example of optimizing the Photo-fenton model using a PPO agent with \"balanced\" memory configuration and \"random\" initialization (called DB-R).\n",
    "\n",
    "We also provide .py files of all agent configuration from this work. These .py files should be run from terminal and must be configured using the exp_config.yaml file.\n",
    "\n",
    "```bash\n",
    "python <file.py> <path to folder containing exp_config.yaml>\n",
    "```\n",
    "\n",
    "E. g.: An optimization of peroxide model using a PPO agent with \"balanced\" memory of experiences and \"random\"\n",
    "initialization should be run as:\n",
    "\n",
    "```bash\n",
    "python Agent_DB-R.py ./\n",
    "```\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from RL_Agent import ppo_agent_continuous_parallel\n",
    "from utils.preprocess import *\n",
    "from utils import hyperparameters as hyperparams\n",
    "from RL_Problem import rl_problem\n",
    "from src.environments import perox_complete_model_small_glob_coord\n",
    "import global_enviroment_log as glob\n",
    "import datetime as dt\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's configure the algorithm parameters. When running out of binder you should use the exp_config.yaml file for this purpose.\n",
    "\n",
    "Here we explain each parameter:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "actor_lr = 1e-5  # actor network learning rate\n",
    "critic_lr = 1e-5  # critic network learning rate\n",
    "batch_size =  128  # batch size for training the network\n",
    "exploration_noise = 5.0  # Maximum value of std in exploration\n",
    "epsilon = 1.0  # Exploration rate\n",
    "epsilon_decay = 0.8   # Exploration decay rate. Rate decay by multipliying epsilon * epsilon_decay\n",
    "epsilon_min = 0.09  # Minimum value for epsilon.\n",
    "memory_size = 40  # Number of experiences stored in memory for each training step\n",
    "histogram_memory = True  # Whether use histogram (or balanced) memory configuration.\n",
    "n_stack = 20  # Number of states from previous time steps used as inputs to the neural network.\n",
    "n_threads = 12  # Number of parallel executions.\n",
    "iter = 252  # Full iterations. Round*n_threads = iter\n",
    "\n",
    "sodis_params = \"src/environments/fotocaos_complete_model/sodis_params.txt\"  # File to the sodis parameters\n",
    "\n",
    "experiment_path = \"experiments/\"  # path to save the logs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load model fixed data:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "glob.traj_path = experiment_path\n",
    "\n",
    "log_alpha_values_init = [1e-5, 1e-5, 1e-5, -15., 1e-5, 1e-5, 1e-5, 1e-5, 1e-5, 1e-5, 1e-5, 1e-5, 1, 1]\n",
    "\n",
    "f = open(sodis_params, \"r\")\n",
    "sodis_params = f.read()\n",
    "sodis_params = sodis_params.split('\\n')\n",
    "sodis_params = [float(sodis_params[i]) for i in range(len(sodis_params)-1)]\n",
    "\n",
    "# Assign Sodis params\n",
    "log_alpha_values_init[6] = sodis_params[0]\n",
    "log_alpha_values_init[10] = sodis_params[1]\n",
    "log_alpha_values_init[13] = np.trunc(sodis_params[2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Build the reinforcement learning environment. This entity includes the Photo-fenton model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/serch/TFM/RLPhotoFentonOptimization/src/environments/fotocaos_complete_model/modelo_completo_perox_interfaz_v2.py:361: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  nuevos_index.append(np.array(index_aux))\n",
      "/home/serch/TFM/RLPhotoFentonOptimization/src/environments/fotocaos_complete_model/modelo_completo_perox_interfaz_v2.py:365: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  nuevos_index.append(np.array(index_aux))\n"
     ]
    }
   ],
   "source": [
    "m_peroxide = perox_complete_model_small_glob_coord.env(sodis=False,\n",
    "                                                       perox=True,\n",
    "                                                       bact=False,\n",
    "                                                       log_alpha_values_init=log_alpha_values_init,\n",
    "                                                       log_scale=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the neural network architecture."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def lstm_custom_model_actor(input_shape):\n",
    "    actor_model = Sequential()\n",
    "    actor_model.add(LSTM(128, input_shape=input_shape, activation='tanh'))\n",
    "    actor_model.add(Dense(256, input_shape=input_shape, activation='relu'))\n",
    "    actor_model.add(Dense(256, input_shape=input_shape, activation='relu'))\n",
    "    actor_model.add(Dense(128, activation='relu'))\n",
    "    return actor_model\n",
    "\n",
    "def lstm_custom_model_critic(input_shape):\n",
    "    actor_model = Sequential()\n",
    "    actor_model.add(LSTM(128, input_shape=input_shape, activation='tanh'))\n",
    "    actor_model.add(Dense(256, input_shape=input_shape, activation='relu'))\n",
    "    actor_model.add(Dense(128, activation='relu'))\n",
    "    return actor_model\n",
    "\n",
    "net_architecture = hyperparams.actor_critic_net_architecture(use_custom_network=True,\n",
    "                                                        actor_custom_network=lstm_custom_model_actor,\n",
    "                                                        critic_custom_network=lstm_custom_model_critic,\n",
    "                                                        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Build a PPO agent."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "agent = ppo_agent_continuous_parallel.Agent(actor_lr=actor_lr,\n",
    "                                            critic_lr=critic_lr,\n",
    "                                            batch_size=batch_size,\n",
    "                                            exploration_noise=exploration_noise,\n",
    "                                            epsilon=epsilon,\n",
    "                                            epsilon_decay=epsilon_decay,\n",
    "                                            epsilon_min=epsilon_min,\n",
    "                                            memory_size=memory_size,\n",
    "                                            net_architecture=net_architecture,\n",
    "                                            n_stack=n_stack,\n",
    "                                            n_step_return=20,\n",
    "                                            histogram_memory=histogram_memory,\n",
    "                                            tensorboard_dir=None,\n",
    "                                            n_parallel_envs=n_threads\n",
    "                                            )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Build a reinforcement learning problem with an environment (the model) and an agent."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/serch/TFM/RLPhotoFentonOptimization/RL_Agent/base/PPO_base/ppo_agent_base.py:35: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n",
      "\n",
      "\u001B[33mWARNING: If you want to specify convolutional layers you must set all the values for the following keys: conv_layers, kernel_num, kernel_size, kernel_strides and conv_activation\u001B[0m\n",
      "\u001B[33mWARNING: If you want to specify dense layers you must set all the values for the following keys: dense_lay, n_neurons and dense_activation\u001B[0m\n",
      "Custom network option selected: {use_custom_network:  True , custom_network:  <function lstm_custom_model_actor at 0x7f62cf8b7950> }\n",
      "WARNING:tensorflow:From /home/serch/anaconda3/envs/fotocaos/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "lstm_input (InputLayer)         [(None, 20, 245)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 128)          191488      lstm_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          33024       lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          32896       dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 5)            645         dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 323,845\n",
      "Trainable params: 323,845\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\u001B[33mWARNING: If you want to specify convolutional layers you must set all the values for the following keys: conv_layers, kernel_num, kernel_size, kernel_strides and conv_activation\u001B[0m\n",
      "\u001B[33mWARNING: If you want to specify dense layers you must set all the values for the following keys: dense_lay, n_neurons and dense_activation\u001B[0m\n",
      "Custom network option selected: {use_custom_network:  True , custom_network:  <function lstm_custom_model_critic at 0x7f62cf8b7bf8> }\n"
     ]
    }
   ],
   "source": [
    "problem = rl_problem.Problem(m_peroxide, agent)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set a preprocessing function."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "problem.preprocess = perox_only_norm\n",
    "problem.compile()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Execute the optimization process. Note that a histogram of the memory is shown when using balanced memory. This histogram shows the number of states for each reward value."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time 2022-05-02 20:28:17.030852\n",
      "Episode  1 Epochs  40  Reward -235.8 Smooth Reward -262.8  Epsilon 1.0000\n",
      "Episode  2 Epochs  40  Reward -235.4 Smooth Reward -262.8  Epsilon 1.0000\n",
      "Episode  3 Epochs  40  Reward -306.3 Smooth Reward -262.8  Epsilon 1.0000\n",
      "Episode  4 Epochs  40  Reward -317.2 Smooth Reward -262.8  Epsilon 1.0000\n",
      "Episode  5 Epochs  40  Reward -234.8 Smooth Reward -262.8  Epsilon 1.0000\n",
      "Episode  6 Epochs  40  Reward -210.8 Smooth Reward -262.8  Epsilon 1.0000\n",
      "Episode  7 Epochs  40  Reward -245.0 Smooth Reward -262.8  Epsilon 1.0000\n",
      "Episode  8 Epochs  40  Reward -276.9 Smooth Reward -262.8  Epsilon 1.0000\n",
      "Episode  9 Epochs  40  Reward -327.2 Smooth Reward -262.8  Epsilon 1.0000\n",
      "Episode  10 Epochs  40  Reward -244.5 Smooth Reward -262.8  Epsilon 1.0000\n",
      "Episode  11 Epochs  40  Reward -243.5 Smooth Reward -262.8  Epsilon 1.0000\n",
      "Episode  12 Epochs  40  Reward -276.2 Smooth Reward -262.8  Epsilon 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAQzklEQVR4nO3df4wcZ33H8fcHJ01biEpSX4JxnDogt2qCioNOLiWoCg1t3CDkIDWVowq5aiqDlEhQ0aoOSCUVspTSAlWlBslAhKloUktAY0FoMS4IUUrCJcovx6QxxE2MLdv8aBP+SRvz7R83Jpvz3t3e7e39ePJ+SaudeeZ5Zr43Hn92bmZ3L1WFJKktL1nqAiRJC89wl6QGGe6S1CDDXZIaZLhLUoPOWuoCAFavXl3r169f6jIkaUW57777vl9VY/2WLYtwX79+PRMTE0tdhiStKEn+a7plXpaRpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGLYtPqA5r/Y4vDNTv8K1vGXElkrQ8eOYuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNmjXck/xsknuTPJjkQJK/7NrPT7IvyePd83k9Y25OcijJY0muHuUPIEk60yBn7s8Cv1VVrwU2ApuTvB7YAeyvqg3A/m6eJJcCW4HLgM3AbUlWjaB2SdI0Zg33mvTjbvbs7lHAFmB3174buLab3gLcWVXPVtUTwCFg00IWLUma2UDX3JOsSvIAcALYV1X3ABdW1TGA7vmCrvta4Kme4Ue6tqnr3J5kIsnEyZMnh/gRJElTDRTuVXWqqjYCFwGbkrxmhu7pt4o+69xVVeNVNT42NjZQsZKkwczp3TJV9d/AV5m8ln48yRqA7vlE1+0IsK5n2EXA0WELlSQNbpB3y4wleXk3/XPAm4FvA3uBbV23bcBd3fReYGuSc5JcAmwA7l3guiVJMxjkj3WsAXZ373h5CbCnqj6f5D+APUluAJ4ErgOoqgNJ9gCPAs8BN1bVqdGUL0nqZ9Zwr6qHgMv7tP8AuGqaMTuBnUNXJ0maFz+hKkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDZg33JOuSfCXJwSQHkryra78lyfeSPNA9rukZc3OSQ0keS3L1KH8ASdKZzhqgz3PAe6rq/iTnAvcl2dct+0hV/U1v5ySXAluBy4BXAl9O8stVdWohC5ckTW/WM/eqOlZV93fTzwAHgbUzDNkC3FlVz1bVE8AhYNNCFCtJGsycrrknWQ9cDtzTNd2U5KEktyc5r2tbCzzVM+wIM78YSJIW2MDhnuRlwGeAd1fV08BHgVcDG4FjwIdOd+0zvPqsb3uSiSQTJ0+enGvdkqQZDBTuSc5mMtg/XVWfBaiq41V1qqp+AnyM5y+9HAHW9Qy/CDg6dZ1VtauqxqtqfGxsbJifQZI0xSDvlgnwCeBgVX24p31NT7e3AY9003uBrUnOSXIJsAG4d+FKliTNZpB3y1wBvB14OMkDXdt7geuTbGTyksth4B0AVXUgyR7gUSbfaXOj75SRpMU1a7hX1dfpfx397hnG7AR2DlGXJGkIfkJVkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUoFnDPcm6JF9JcjDJgSTv6trPT7IvyePd83k9Y25OcijJY0muHuUPIEk60yBn7s8B76mqXwVeD9yY5FJgB7C/qjYA+7t5umVbgcuAzcBtSVaNonhJUn+zhntVHauq+7vpZ4CDwFpgC7C767YbuLab3gLcWVXPVtUTwCFg0wLXLUmawZyuuSdZD1wO3ANcWFXHYPIFALig67YWeKpn2JGubeq6tieZSDJx8uTJeZQuSZrOwOGe5GXAZ4B3V9XTM3Xt01ZnNFTtqqrxqhofGxsbtAxJ0gAGCvckZzMZ7J+uqs92zceTrOmWrwFOdO1HgHU9wy8Cji5MuZKkQQzybpkAnwAOVtWHexbtBbZ109uAu3ratyY5J8klwAbg3oUrWZI0m7MG6HMF8Hbg4SQPdG3vBW4F9iS5AXgSuA6gqg4k2QM8yuQ7bW6sqlMLXbgkaXqzhntVfZ3+19EBrppmzE5g5xB1SZKG4CdUJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWrQrOGe5PYkJ5I80tN2S5LvJXmge1zTs+zmJIeSPJbk6lEVLkma3iBn7p8ENvdp/0hVbewedwMkuRTYClzWjbktyaqFKlaSNJhZw72qvgb8cMD1bQHurKpnq+oJ4BCwaYj6JEnzMMw195uSPNRdtjmva1sLPNXT50jXdoYk25NMJJk4efLkEGVIkqaab7h/FHg1sBE4Bnyoa0+fvtVvBVW1q6rGq2p8bGxsnmVIkvqZV7hX1fGqOlVVPwE+xvOXXo4A63q6XgQcHa5ESdJczSvck6zpmX0bcPqdNHuBrUnOSXIJsAG4d7gSJUlzddZsHZLcAVwJrE5yBHg/cGWSjUxecjkMvAOgqg4k2QM8CjwH3FhVp0ZSuSRpWrOGe1Vd36f5EzP03wnsHKYoSdJw/ISqJDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ2aNdyT3J7kRJJHetrOT7IvyePd83k9y25OcijJY0muHlXhkqTpDXLm/klg85S2HcD+qtoA7O/mSXIpsBW4rBtzW5JVC1atJGkgs4Z7VX0N+OGU5i3A7m56N3BtT/udVfVsVT0BHAI2LUypkqRBzfea+4VVdQyge76ga18LPNXT70jXdoYk25NMJJk4efLkPMuQJPWz0DdU06et+nWsql1VNV5V42NjYwtchiS9uM033I8nWQPQPZ/o2o8A63r6XQQcnX95kqT5mG+47wW2ddPbgLt62rcmOSfJJcAG4N7hSpQkzdVZs3VIcgdwJbA6yRHg/cCtwJ4kNwBPAtcBVNWBJHuAR4HngBur6tSIapckTWPWcK+q66dZdNU0/XcCO4cpSpI0HD+hKkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDzhpmcJLDwDPAKeC5qhpPcj7wT8B64DDw+1X1o+HKlCTNxUKcub+pqjZW1Xg3vwPYX1UbgP3dvCRpEQ115j6NLcCV3fRu4KvAn49gOy9a63d8YeC+h299ywgrkbRcDXvmXsCXktyXZHvXdmFVHQPoni8YchuSpDka9sz9iqo6muQCYF+Sbw86sHsx2A5w8cUXD1mGJKnXUGfuVXW0ez4BfA7YBBxPsgagez4xzdhdVTVeVeNjY2PDlCFJmmLe4Z7kpUnOPT0N/A7wCLAX2NZ12wbcNWyRkqS5GeayzIXA55KcXs8/VtW/JPkWsCfJDcCTwHXDlylJmot5h3tVfRd4bZ/2HwBXDVOUJGk4fkJVkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lq0Cj+EpO0Igz6F638a1ZaiTxzl6QGGe6S1CDDXZIa5DX3xnldWXpx8sxdkhpkuEtSg7wsswi8NCJpsXnmLkkNMtwlqUFelllGBr18I0mzMdwFeF9gJu4brUSGu+bEoJNWhpFdc0+yOcljSQ4l2TGq7UiSzjSSM/ckq4C/B34bOAJ8K8neqnp0FNvT8rPQZ/j+xiDNzaguy2wCDlXVdwGS3AlsAQx3vcBC30ReypvSC73thX6hmkt9S/WiuxJexFdCjQCpqoVfafJ7wOaq+uNu/u3Ar1fVTT19tgPbu9lfAR6bZnWrge8veJGjs9LqBWteLCut5pVWL7z4av6lqhrrt2BUZ+7p0/aCV5Gq2gXsmnVFyURVjS9UYaO20uoFa14sK63mlVYvWHOvUd1QPQKs65m/CDg6om1JkqYYVbh/C9iQ5JIkPwNsBfaOaFuSpClGclmmqp5LchPwr8Aq4PaqOjDP1c166WaZWWn1gjUvlpVW80qrF6z5p0ZyQ1WStLT84jBJapDhLkkNWvJwT3J+kn1JHu+ez+vTZ12SryQ5mORAknf1LLslyfeSPNA9rhlhrTN+pUIm/V23/KEkrxt07BLW/AddrQ8l+UaS1/YsO5zk4W6/TiyTeq9M8j89/95/MejYJaz5z3rqfSTJqSTnd8uWYh/fnuREkkemWb4cj+PZal5Wx/GANY/2WK6qJX0AHwR2dNM7gL/q02cN8Lpu+lzgP4FLu/lbgD9dhDpXAd8BXgX8DPDg6Rp6+lwDfJHJ9/m/Hrhn0LFLWPMbgPO66d89XXM3fxhYvYjHwiD1Xgl8fj5jl6rmKf3fCvzbUu3jbpu/CbwOeGSa5cvqOB6w5mVzHM+h5pEey0t+5s7k1xLs7qZ3A9dO7VBVx6rq/m76GeAgsHaxCuz89CsVqup/gdNfqdBrC/CpmvRN4OVJ1gw4dklqrqpvVNWPutlvMvmZhKUyzH5atvt4iuuBOxahrmlV1deAH87QZbkdx7PWvMyOY2Cg/TydBdnPyyHcL6yqYzAZ4sAFM3VOsh64HLinp/mm7tex2/td1lkga4GneuaPcOYLzHR9Bhk7CnPd7g1MnrGdVsCXktyXya+LGLVB6/2NJA8m+WKSy+Y4dqENvN0kPw9sBj7T07zY+3gQy+04nqulPo7nYmTH8qJ8n3uSLwOv6LPofXNcz8uY/I/x7qp6umv+KPABJv8BPwB8CPij+Vc7/eb7tE19H+l0fQYZOwoDbzfJm5j8T/HGnuYrqupokguAfUm+3Z2NjMog9d7P5Pdp/Li7v/LPwIYBx47CXLb7VuDfq6r3bG6x9/EglttxPLBlchwPaqTH8qKcuVfVm6vqNX0edwHHu1/56J5P9FtHkrOZDPZPV9Vne9Z9vKpOVdVPgI8x+SvNKAzylQrT9Vmqr2MYaLtJfg34OLClqn5wur2qjnbPJ4DPMbp9e9qs9VbV01X14276buDsJKsHGTsic9nuVqZcklmCfTyI5XYcD2QZHccDGfmxvNg3GfrcPPhrXnhD9YN9+gT4FPC3fZat6Zn+E+DOEdV5FvBd4BKev8lx2ZQ+b+GFN6LuHXTsEtZ8MXAIeMOU9pcC5/ZMf4PJb/pc6npfwfMfvtsEPNnt72W7j7t+v8Dk9deXLuU+7tn2eqa/0besjuMBa142x/Ecah7psbwoP+AsP/wvAvuBx7vn87v2VwJ3d9NvZPLXkoeAB7rHNd2yfwAe7pbtpSfsR1DrNUy+U+c7wPu6tncC7+ymw+QfKflOV9P4TGMXaf/OVvPHgR/17NeJrv1V3UH1IHBgsWoeoN6bunoeZPLG2RtmGrscau7m/5ApJx5LuI/vAI4B/8fkWeINK+A4nq3mZXUcD1jzSI9lv35Akhq0HN4tI0laYIa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJatD/Ax+czIy/SCmZAAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/serch/anaconda3/envs/fotocaos/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/serch/TFM/RLPhotoFentonOptimization/RL_Agent/base/PPO_base/ppo_agent_base.py:393: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  global_error = np.array(self.best_params_fotocaos_list)[:, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor loss 787.3103678385417 0\n",
      "Critic loss 1554.588045247396 0\n",
      "Episode  13 Epochs  40  Reward -253.2 Smooth Reward -259.7  Epsilon 0.8000\n",
      "Episode  14 Epochs  40  Reward -255.9 Smooth Reward -259.7  Epsilon 0.8000\n",
      "Episode  15 Epochs  40  Reward -255.0 Smooth Reward -259.7  Epsilon 0.8000\n",
      "Episode  16 Epochs  40  Reward -244.4 Smooth Reward -259.7  Epsilon 0.8000\n",
      "Episode  17 Epochs  40  Reward -265.9 Smooth Reward -259.7  Epsilon 0.8000\n",
      "Episode  18 Epochs  40  Reward -286.3 Smooth Reward -259.7  Epsilon 0.8000\n",
      "Episode  19 Epochs  40  Reward -223.7 Smooth Reward -259.7  Epsilon 0.8000\n",
      "Episode  20 Epochs  40  Reward -256.4 Smooth Reward -259.7  Epsilon 0.8000\n",
      "Episode  21 Epochs  40  Reward -276.1 Smooth Reward -259.7  Epsilon 0.8000\n",
      "Episode  22 Epochs  40  Reward -286.1 Smooth Reward -259.7  Epsilon 0.8000\n",
      "Episode  23 Epochs  40  Reward -224.2 Smooth Reward -259.7  Epsilon 0.8000\n",
      "Episode  24 Epochs  40  Reward -252.7 Smooth Reward -259.7  Epsilon 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor loss 536.1685233738111 1\n",
      "Critic loss 1054.2254712975543 1\n",
      "End time 2022-05-02 20:29:50.074157\n",
      "Optimization time 0:01:33.043305\n"
     ]
    }
   ],
   "source": [
    "start_time = dt.datetime.now()\n",
    "print('Start time', start_time)\n",
    "\n",
    "problem.solve(iter, render=False)\n",
    "\n",
    "end_time = dt.datetime.now()\n",
    "opt_time = end_time - start_time\n",
    "\n",
    "print('End time', end_time)\n",
    "print('Optimization time', opt_time)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Show the best set of params found for the peroxide model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peroxide params (K_M_P):  [-0.53922129 -1.46990596 -0.7196868   0.85200202 -2.10898331]\n",
      "Model error:  0.4295404604460738\n"
     ]
    }
   ],
   "source": [
    "best_parallel_params_list = problem.env.get_best_params()\n",
    "\n",
    "params_list = []\n",
    "for params in best_parallel_params_list:\n",
    "    params_list.extend(params)\n",
    "\n",
    "if len(params_list) > 0:\n",
    "    ind_best = np.argmin(np.array(params_list)[:, 1])\n",
    "    model_params, model_error = params_list[ind_best][0], params_list[ind_best][1]\n",
    "\n",
    "print('Peroxide params (K_M_P): ', model_params)\n",
    "print('Peroxide model error: ', model_error)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next we are going to optimize the bacteria model. First thing we need is to assign the optimized parameters of the peroxide model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "log_alpha_values_init[0] = model_params[0]\n",
    "log_alpha_values_init[1] = model_params[1]\n",
    "log_alpha_values_init[2] = model_params[2]\n",
    "log_alpha_values_init[4] = model_params[3]\n",
    "log_alpha_values_init[5] = model_params[4]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's configure the algorithm parameters for the bacteria model optimization.\n",
    "\n",
    "Here we explain each parameter:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "actor_lr = 1e-5  # actor network learning rate\n",
    "critic_lr = 1e-5  # critic network learning rate\n",
    "batch_size =  128  # batch size for training the network\n",
    "exploration_noise = 5.0  # Maximum value of std in exploration\n",
    "epsilon = 1.0  # Exploration rate\n",
    "epsilon_decay = 0.8   # Exploration decay rate. Rate decay by multipliying epsilon * epsilon_decay\n",
    "epsilon_min = 0.09  # Minimum value for epsilon.\n",
    "memory_size = 40  # Number of experiences stored in memory for each training step\n",
    "histogram_memory = True  # Whether use histogram (or balanced) memory configuration.\n",
    "n_stack = 20  # Number of states from previous time steps used as inputs to the neural network.\n",
    "n_threads = 12  # Number of parallel executions.\n",
    "iter = 12 # 252  # Full iterations. Round*n_threads = iter"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's build the environment for the bacteria model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "m_bacteria = perox_complete_model_small_glob_coord.env(sodis=False,\n",
    "                                                       perox=False,\n",
    "                                                       bact=True,\n",
    "                                                       log_alpha_values_init=log_alpha_values_init,\n",
    "                                                       log_scale=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next we create a new agent to start a new optimization process as we did in our experiments. We could also use the previous agent pretrained in the peroxide model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "bacteria_agent = ppo_agent_continuous_parallel.Agent(actor_lr=actor_lr,\n",
    "                                            critic_lr=critic_lr,\n",
    "                                            batch_size=batch_size,\n",
    "                                            exploration_noise=exploration_noise,\n",
    "                                            epsilon=epsilon,\n",
    "                                            epsilon_decay=epsilon_decay,\n",
    "                                            epsilon_min=epsilon_min,\n",
    "                                            memory_size=memory_size,\n",
    "                                            net_architecture=net_architecture,\n",
    "                                            n_stack=n_stack,\n",
    "                                            n_step_return=20,\n",
    "                                            histogram_memory=histogram_memory,\n",
    "                                            tensorboard_dir=None,\n",
    "                                            n_parallel_envs=n_threads\n",
    "                                            )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Build a reinforcement learning problem with an environment (the model) and an agent."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "bacteria_problem = rl_problem.Problem(m_bacteria, agent)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set a preprocessing function."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "bacteria_problem.preprocess = bact_only_norm\n",
    "bacteria_problem.compile()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Execute the optimization process. Note that a histogram of the memory is shown when using balanced memory. This histogram shows the number of states for each reward value."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time 2022-05-02 20:51:22.976605\n"
     ]
    }
   ],
   "source": [
    "start_time = dt.datetime.now()\n",
    "print('Start time', start_time)\n",
    "\n",
    "bacteria_problem.solve(iter, render=False)\n",
    "\n",
    "end_time = dt.datetime.now()\n",
    "opt_time = end_time - start_time\n",
    "\n",
    "print('End time', end_time)\n",
    "print('Optimization time', opt_time)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Show the best set of params found for the bacteria model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_parallel_params_list = bacteria_problem.env.get_best_params()\n",
    "\n",
    "params_list = []\n",
    "for params in best_parallel_params_list:\n",
    "    params_list.extend(params)\n",
    "\n",
    "if len(params_list) > 0:\n",
    "    ind_best = np.argmin(np.array(params_list)[:, 1])\n",
    "    model_params, model_error = params_list[ind_best][0], params_list[ind_best][1]\n",
    "\n",
    "print('Bacteria params (K_M_B): ', model_params)\n",
    "print('Bacteria model error: ', model_error)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Show results:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from src.environments.fotocaos_complete_model import modelo_completo_perox_interfaz\n",
    "model = modelo_completo_perox_interfaz.ModeloCinetico(perox=True, bact=True, sodis=True,\n",
    "                                                      params_to_optimize=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])\n",
    "log_alpha_values_init[0] = model_params[0]\n",
    "log_alpha_values_init[1] = model_params[1]\n",
    "log_alpha_values_init[2] = model_params[2]\n",
    "log_alpha_values_init[4] = model_params[3]\n",
    "log_alpha_values_init[5] = model_params[4]\n",
    "params = log_alpha_values_init\n",
    "\n",
    "error, curvas, params = model.reset(params=np.array(params))\n",
    "model.render(error, curvas, params, 0., perox=True, bact=True, sodis=True)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}